{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scientific Claim Retrieval: Complete Evaluation Workflow\n",
    "\n",
    "This notebook:\n",
    "1. Evaluates all models on the dev set\n",
    "2. Identifies the best performing model\n",
    "3. Generates test set predictions using the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "349c5570",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/at043650/Desktop/github-private/paperQuest/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/at043650/Desktop/github-private/paperQuest/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "from evaluator import evaluate_models\n",
    "import json\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d407eb1d",
   "metadata": {},
   "source": [
    "## Step 1: Define Full Configuration for All Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82322f64",
   "metadata": {},
   "source": [
    "Available Models:\n",
    "```\n",
    "        # Traditional methods\n",
    "        'bm25',              # Basic BM25\n",
    "        'tfidf',             # Basic TF-IDF\n",
    "        \n",
    "        # Representation learning  \n",
    "        'custom_retriever',          # Dense semantic embeddings\n",
    "        'vector_store',      # Vector database retrieval\n",
    "        \n",
    "        # Reranking methods\n",
    "        'bm25_reranker',     # BM25 + neural reranking\n",
    "        'tfidf_reranker',    # TF-IDF + neural reranking\n",
    "        'custom_retriever_reranker', # Two-stage with neural reranking\n",
    "        'vector_store_reranker', # Vector store + reranking\n",
    "        \n",
    "        # Hybrid methods\n",
    "        'multi_stage_hybrid',      # retrieve, fuse, rerank\n",
    "        \n",
    "        # Query expansion\n",
    "        'query_expansion'    # LLM-enhanced queries\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57d35ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEV_CONFIG = {\n",
    "    # Data paths\n",
    "    'collection_path': 'data/subtask4b_collection_data.pkl',\n",
    "    'query_path': 'data/subtask4b_query_tweets_dev.tsv',\n",
    "    \n",
    "    # Available model categories and names:\n",
    "    'models': [\n",
    "        # Traditional methods\n",
    "        'bm25',              # Basic BM25\n",
    "        'tfidf',             # Basic TF-IDF\n",
    "        \n",
    "        # Representation learning  \n",
    "        'custom_retriever',          # Dense semantic embeddings\n",
    "        'vector_store',      # Vector database retrieval\n",
    "        \n",
    "        # Reranking methods\n",
    "        'bm25_reranker',     # BM25 + neural reranking\n",
    "        'tfidf_reranker',    # TF-IDF + neural reranking\n",
    "        'custom_retriever_reranker', # Two-stage with neural reranking\n",
    "        'vector_store_reranker', # Vector store + reranking\n",
    "        \n",
    "        # Hybrid methods\n",
    "        'multi_stage_hybrid',      # retrieve, fuse, rerank\n",
    "        \n",
    "        # Query expansion\n",
    "        'query_expansion'    # LLM-enhanced queries\n",
    "    ], \n",
    "    \n",
    "    # Output settings\n",
    "    'output_dir': f'results/eval_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}',\n",
    "    \n",
    "    # Model configuration\n",
    "    'top_k': 5,\n",
    "    'mrr_k': [1, 5, 10],\n",
    "    'collection_columns': ['title', 'abstract'],\n",
    "    \n",
    "    # Model-specific settings\n",
    "    'embedding_model': 'sentence-transformers/allenai-specter',\n",
    "    'vectordb_model': 'all-minilm', # 'nomic-embed-text', #  'all-minilm', // momic performs worse\n",
    "    'reranker_model': 'cross-encoder/ms-marco-MiniLM-L-6-v2', # 'BAAI/bge-reranker-base', #\n",
    "    \n",
    "    # Hybrid settings\n",
    "    'rrf_k': 60,\n",
    "    'sparse_weight': 0.6,\n",
    "    \n",
    "    # Performance settings\n",
    "    'candidate_count': 50,\n",
    "    'batch_size': 32,\n",
    "    'reranker_batch_size': 8,\n",
    "    'use_gpu': True,\n",
    "\n",
    "    # Sampling for testing\n",
    "    'sample_size': None, # tweets\n",
    "    'collection_sample_size': None, # abstracts\n",
    "    \n",
    "    'cache_dir': 'cache',\n",
    "    'show_progress': False,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19a6a1c",
   "metadata": {},
   "source": [
    "## Step 2: Evaluate All Models on Dev Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43b54751",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-30 12:19:59,829 - INFO - Running bm25...\n",
      "Processing bm25: 100%|██████████| 1400/1400 [00:40<00:00, 34.92it/s]\n",
      "2025-05-30 12:20:41,180 - INFO - bm25 MRR@5: 0.5590\n",
      "2025-05-30 12:20:41,184 - INFO - Running tfidf...\n",
      "Processing tfidf: 100%|██████████| 1400/1400 [00:08<00:00, 159.25it/s]\n",
      "2025-05-30 12:20:52,803 - INFO - tfidf MRR@5: 0.5092\n",
      "2025-05-30 12:20:52,806 - INFO - Running custom_retriever...\n",
      "Processing custom_retriever: 100%|██████████| 1400/1400 [00:26<00:00, 52.38it/s]\n",
      "2025-05-30 12:24:50,521 - INFO - custom_retriever MRR@5: 0.3252\n",
      "2025-05-30 12:24:50,524 - INFO - Running vector_store...\n",
      "Creating documents: 100%|██████████| 7718/7718 [00:00<00:00, 47741.27it/s]\n",
      "Processing vector_store: 100%|██████████| 1400/1400 [00:19<00:00, 70.02it/s]\n",
      "2025-05-30 12:26:17,841 - INFO - vector_store MRR@5: 0.4847\n",
      "2025-05-30 12:26:17,845 - INFO - Running bm25_reranker...\n",
      "Processing bm25_reranker: 100%|██████████| 1400/1400 [11:09<00:00,  2.09it/s]\n",
      "2025-05-30 12:37:39,703 - INFO - bm25_reranker MRR@5: 0.6069\n",
      "2025-05-30 12:37:39,707 - INFO - Running tfidf_reranker...\n",
      "Processing tfidf_reranker: 100%|██████████| 1400/1400 [10:22<00:00,  2.25it/s]\n",
      "2025-05-30 12:48:16,174 - INFO - tfidf_reranker MRR@5: 0.6189\n",
      "2025-05-30 12:48:16,177 - INFO - Running custom_retriever_reranker...\n",
      "Processing custom_retriever_reranker: 100%|██████████| 1400/1400 [12:38<00:00,  1.85it/s]\n",
      "2025-05-30 13:04:30,476 - INFO - custom_retriever_reranker MRR@5: 0.5594\n",
      "2025-05-30 13:04:30,481 - INFO - Running vector_store_reranker...\n",
      "Creating documents: 100%|██████████| 7718/7718 [00:00<00:00, 26803.53it/s]\n",
      "Processing vector_store_reranker: 100%|██████████| 1400/1400 [11:40<00:00,  2.00it/s]\n",
      "2025-05-30 13:17:29,888 - INFO - vector_store_reranker MRR@5: 0.5820\n",
      "2025-05-30 13:17:29,893 - INFO - Running multi_stage_hybrid...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid retriever using device: mps\n",
      "Building hybrid retrieval indices...\n",
      "Building sparse index (BM25)...\n",
      "Building dense embeddings...\n",
      "Building FAISS index...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing multi_stage_hybrid: 100%|██████████| 1400/1400 [10:57<00:00,  2.13it/s]\n",
      "2025-05-30 13:32:06,508 - INFO - multi_stage_hybrid MRR@5: 0.6209\n",
      "2025-05-30 13:32:06,512 - INFO - Running query_expansion...\n",
      "Creating documents: 100%|██████████| 7718/7718 [00:00<00:00, 46389.20it/s]\n",
      "Processing query_expansion: 100%|██████████| 1400/1400 [42:44<00:00,  1.83s/it]\n",
      "2025-05-30 14:15:59,298 - INFO - query_expansion MRR@5: 0.4920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation completed! Results saved to: results/eval_20250530_121959\n"
     ]
    }
   ],
   "source": [
    "# Run evaluation\n",
    "dev_results = evaluate_models(DEV_CONFIG)\n",
    "\n",
    "print(f\"\\nEvaluation completed! Results saved to: {dev_results['output_dir']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8491dc",
   "metadata": {},
   "source": [
    "## Step 3: Display Results and Find Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ada252c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Dev Set Evaluation Results ===\n",
      "\n",
      "bm25:\n",
      "  MRR@1: 0.5114\n",
      "  MRR@5: 0.5590\n",
      "  MRR@10: 0.5590\n",
      "\n",
      "tfidf:\n",
      "  MRR@1: 0.4407\n",
      "  MRR@5: 0.5092\n",
      "  MRR@10: 0.5092\n",
      "\n",
      "custom_retriever:\n",
      "  MRR@1: 0.2671\n",
      "  MRR@5: 0.3252\n",
      "  MRR@10: 0.3252\n",
      "\n",
      "vector_store:\n",
      "  MRR@1: 0.4100\n",
      "  MRR@5: 0.4847\n",
      "  MRR@10: 0.4847\n",
      "\n",
      "bm25_reranker:\n",
      "  MRR@1: 0.5579\n",
      "  MRR@5: 0.6069\n",
      "  MRR@10: 0.6069\n",
      "\n",
      "tfidf_reranker:\n",
      "  MRR@1: 0.5636\n",
      "  MRR@5: 0.6189\n",
      "  MRR@10: 0.6189\n",
      "\n",
      "custom_retriever_reranker:\n",
      "  MRR@1: 0.5236\n",
      "  MRR@5: 0.5594\n",
      "  MRR@10: 0.5594\n",
      "\n",
      "vector_store_reranker:\n",
      "  MRR@1: 0.5564\n",
      "  MRR@5: 0.5820\n",
      "  MRR@10: 0.5820\n",
      "\n",
      "multi_stage_hybrid:\n",
      "  MRR@1: 0.5721\n",
      "  MRR@5: 0.6209\n",
      "  MRR@10: 0.6209\n",
      "\n",
      "query_expansion:\n",
      "  MRR@1: 0.4221\n",
      "  MRR@5: 0.4920\n",
      "  MRR@10: 0.4920\n",
      "\n",
      "==============================\n",
      "Best model: multi_stage_hybrid (MRR@5: 0.6209)\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "# Display results for all models\n",
    "print(\"=== Dev Set Evaluation Results ===\")\n",
    "\n",
    "if dev_results['metrics']:\n",
    "    for model_name, metrics in dev_results['metrics'].items():\n",
    "        print(f\"\\n{model_name}:\")\n",
    "        print(f\"  MRR@1: {metrics[1]:.4f}\")\n",
    "        print(f\"  MRR@5: {metrics[5]:.4f}\")\n",
    "        print(f\"  MRR@10: {metrics[10]:.4f}\")\n",
    "    \n",
    "    # Find best model based on MRR@5\n",
    "    best_model = max(dev_results['metrics'].items(), key=lambda x: x[1][5])[0]\n",
    "    best_score = dev_results['metrics'][best_model][5]\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 30)\n",
    "    print(f\"Best model: {best_model} (MRR@5: {best_score:.4f})\")\n",
    "    print(\"=\" * 30)\n",
    "else:\n",
    "    print(\"No evaluation metrics available (test set mode)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05116ef1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8421e67a",
   "metadata": {},
   "source": [
    "## Step 4: Create Configuration for Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04366e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating test configuration for model: multi_stage_hybrid\n",
      "\n",
      "Test configuration created:\n",
      "{\n",
      "  \"collection_path\": \"data/subtask4b_collection_data.pkl\",\n",
      "  \"query_path\": \"data/subtask4b_query_tweets_test.tsv\",\n",
      "  \"models\": [\n",
      "    \"multi_stage_hybrid\"\n",
      "  ],\n",
      "  \"output_dir\": \"results/test_multi_stage_hybrid_20250530_141559\",\n",
      "  \"top_k\": 5,\n",
      "  \"collection_columns\": [\n",
      "    \"title\",\n",
      "    \"abstract\"\n",
      "  ],\n",
      "  \"cache_dir\": \"cache\",\n",
      "  \"batch_size\": 32,\n",
      "  \"use_gpu\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Extract relevant configuration parameters for the best model\n",
    "print(f\"Creating test configuration for model: {best_model}\")\n",
    "\n",
    "# Start with the base configuration\n",
    "TEST_CONFIG = {\n",
    "\n",
    "    'collection_path': DEV_CONFIG['collection_path'],\n",
    "    'query_path': 'data/subtask4b_query_tweets_test.tsv',  # Test set for final submission\n",
    "\n",
    "    # Use only the best model\n",
    "    'models': [best_model],\n",
    "\n",
    "    'output_dir': f'results/test_{best_model}_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}',\n",
    "    \n",
    "    # Copy relevant settings from dev config\n",
    "    'top_k': DEV_CONFIG['top_k'],\n",
    "    'collection_columns': DEV_CONFIG['collection_columns'],\n",
    "    'cache_dir': DEV_CONFIG['cache_dir'],\n",
    "    'batch_size': DEV_CONFIG['batch_size'],\n",
    "    'use_gpu': DEV_CONFIG['use_gpu'],\n",
    "}\n",
    "\n",
    "# Add settings based on the best model type\n",
    "if 'langchain' in best_model:\n",
    "    TEST_CONFIG['langchain_embedding'] = DEV_CONFIG['vectordb_model']\n",
    "    TEST_CONFIG['candidate_count'] = DEV_CONFIG['candidate_count']\n",
    "    \n",
    "    if 'reranker' in best_model:\n",
    "        TEST_CONFIG['reranker_model'] = DEV_CONFIG['reranker_model']\n",
    "        TEST_CONFIG['reranker_batch_size'] = DEV_CONFIG['reranker_batch_size']\n",
    "    \n",
    "    if 'query_expansion' in best_model:\n",
    "        TEST_CONFIG['sample_for_expansion'] = DEV_CONFIG['sample_for_expansion']\n",
    "\n",
    "elif best_model == 'dense':\n",
    "    TEST_CONFIG['embedding_model'] = DEV_CONFIG['embedding_model']\n",
    "\n",
    "elif best_model == 'neural_rerank':\n",
    "    TEST_CONFIG['reranker_model'] = DEV_CONFIG['reranker_model']\n",
    "    TEST_CONFIG['reranker_batch_size'] = DEV_CONFIG['reranker_batch_size']\n",
    "    TEST_CONFIG['candidate_count'] = DEV_CONFIG['candidate_count']\n",
    "\n",
    "print(\"\\nTest configuration created:\")\n",
    "print(json.dumps(TEST_CONFIG, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee9afd6",
   "metadata": {},
   "source": [
    "## Step 5: Generate Test Set Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "686638a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-30 14:15:59,344 - INFO - Running multi_stage_hybrid...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating test predictions using multi_stage_hybrid...\n",
      "Hybrid retriever using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing multi_stage_hybrid: 100%|██████████| 1446/1446 [23:12<00:00,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test predictions completed!\n",
      "Prediction file saved to: results/test_multi_stage_hybrid_20250530_141559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Generating test predictions using {best_model}...\")\n",
    "\n",
    "# Run prediction on test set\n",
    "test_results = evaluate_models(TEST_CONFIG)\n",
    "\n",
    "print(\"\\nTest predictions completed!\")\n",
    "print(f\"Prediction file saved to: {test_results['output_dir']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1f73db",
   "metadata": {},
   "source": [
    "## Step 6: Save Complete Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eebaa517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Complete evaluation summary saved to: results/evaluation_summary_20250530_143926.json\n",
      "\n",
      "=== EVALUATION COMPLETE ===\n",
      "1. Evaluated 10 models on dev set\n",
      "2. Best model: multi_stage_hybrid (MRR@5: 0.6209)\n",
      "3. Test predictions generated and saved\n",
      "\n",
      "All results are in the 'results' directory.\n"
     ]
    }
   ],
   "source": [
    "# Create summary of the entire evaluation process\n",
    "summary = {\n",
    "    'evaluation_date': datetime.now().isoformat(),\n",
    "    'dev_results': {\n",
    "        'metrics': dev_results['metrics'],\n",
    "        'best_model': best_model,\n",
    "        'best_score': best_score,\n",
    "        'output_dir': dev_results['output_dir']\n",
    "    },\n",
    "    'test_results': {\n",
    "        'model_used': best_model,\n",
    "        'output_dir': test_results['output_dir'],\n",
    "        'config': TEST_CONFIG\n",
    "    }\n",
    "}\n",
    "\n",
    "summary_file = f'results/evaluation_summary_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.json'\n",
    "with open(summary_file, 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(f\"\\nComplete evaluation summary saved to: {summary_file}\")\n",
    "\n",
    "print(\"\\n=== EVALUATION COMPLETE ===\")\n",
    "print(f\"1. Evaluated {len(dev_results['metrics'])} models on dev set\")\n",
    "print(f\"2. Best model: {best_model} (MRR@5: {best_score:.4f})\")\n",
    "print(\"3. Test predictions generated and saved\")\n",
    "print(\"\\nAll results are in the 'results' directory.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
